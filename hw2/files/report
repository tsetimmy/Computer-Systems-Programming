The Optimal Optimizers
Timmy Rong Tian Tse (998182657)
timmy.tse@mail.utoronto.ca
Yuan Xue (998275851)
yuan.xue@mail.utoronto.ca

In our final implementation, we achieved a 3.0 - 3.1 speedup by using multi-layered tiling and loop reordering. With multi-layered tiling, we used rectangular tiles, and we tiled the block in three times. In other words, we tiled the block, then we tiled the tiled blocks and then we tiled the tiled tiled blocks. We used multi-layered tiling and rectangular dimension tiling because we believe these techniques help the elements fit into the cache better. Perhaps also layering the tiles helps with caching because of the hierarchy with which caches are organized (L1 and L2 caches). In the end, we relied on trial and error to find the optimal dimensions for our tiles. We opted for 512 by 256, 32 by 32, and 8 by 8 if the dim has greater than 512 and 16 by 16 otherwise. With loop-reordering, we exchanged the order of the i and j iterator and it increased the speedup by approximately 0.2 - 0.4. This reordering works because it produces a row-major access for the destination and a column-major access for the source. If we think in terms of transistor-level, we will understand why this would lead to a speedup: a store requires a change in charge in the transistor whereas a read is just a read in charge and thus, a store will always be the slower operation. Prioritizing the store (the slower operation) with row-column major access over the load will therefore, speedup the execution. Last, we attempted loop unrolling, however, this method did not work for us.
